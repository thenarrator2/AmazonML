{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thenarrator2/AmazonML/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fksd61tciCo2"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import hashlib\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU0jWMa3iM6C",
        "outputId": "7dfa72d1-b670-4e31-a9e4-536843399829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Failed to open image in RGB mode: image file is truncated (3 bytes not processed)\n",
            "WARNING:root:Failed to open image in RGBA mode: image file is truncated (3 bytes not processed)\n",
            "WARNING:root:Failed to open image in L mode: image file is truncated (3 bytes not processed)\n",
            "ERROR:root:Error opening image https://m.media-amazon.com/images/I/41hO04updoL.jpg: Failed to open image in any mode\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from PIL import Image\n",
        "import hashlib\n",
        "import requests\n",
        "import logging\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Directory to save preprocessed images\n",
        "processed_images_dir = 'processed_images'\n",
        "\n",
        "if not os.path.exists(processed_images_dir):\n",
        "    os.makedirs(processed_images_dir)\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(filename='image_processing.log', level=logging.INFO)\n",
        "\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep=',')\n",
        "    required_columns = ['image_link', 'group_id', 'entity_name', 'entity_value', 'text']\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            raise KeyError(f\"Required column '{col}' not found in the dataset\")\n",
        "    return df\n",
        "\n",
        "def process_image(image_url, target_size=(224, 224)):\n",
        "    image_hash = hashlib.md5(image_url.encode()).hexdigest()\n",
        "    image_filename = os.path.join(processed_images_dir, image_hash + '.npy')\n",
        "\n",
        "    if os.path.exists(image_filename):\n",
        "        logging.info(f\"Loading cached image: {image_filename}\")\n",
        "        try:\n",
        "            return np.load(image_filename)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading cached image {image_filename}: {e}\")\n",
        "            return np.zeros(target_size + (3,))\n",
        "    else:\n",
        "        try:\n",
        "            response = requests.get(image_url, stream=True, timeout=10)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Read the content into a BytesIO object\n",
        "            img_data = BytesIO(response.content)\n",
        "\n",
        "            # Try different modes to open the image\n",
        "            for mode in ['RGB', 'RGBA', 'L']:\n",
        "                try:\n",
        "                    img = Image.open(img_data).convert(mode)\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    logging.warning(f\"Failed to open image in {mode} mode: {e}\")\n",
        "            else:\n",
        "                raise IOError(\"Failed to open image in any mode\")\n",
        "\n",
        "            img = img.resize(target_size)\n",
        "            img_array = np.array(img) / 255.0\n",
        "\n",
        "            # Ensure the array has 3 channels\n",
        "            if len(img_array.shape) == 2:\n",
        "                img_array = np.stack((img_array,) * 3, axis=-1)\n",
        "            elif img_array.shape[2] == 4:\n",
        "                img_array = img_array[:,:,:3]\n",
        "\n",
        "            np.save(image_filename, img_array)\n",
        "            logging.info(f\"Processed and cached image: {image_filename}\")\n",
        "\n",
        "            return img_array\n",
        "        except requests.RequestException as e:\n",
        "            logging.error(f\"Error downloading image {image_url}: {e}\")\n",
        "        except IOError as e:\n",
        "            logging.error(f\"Error opening image {image_url}: {e}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Unexpected error processing image {image_url}: {e}\")\n",
        "\n",
        "        return np.zeros(target_size + (3,))\n",
        "\n",
        "def process_text(text, max_length=100):\n",
        "    if pd.isna(text):\n",
        "        text = \"\"\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts([text])\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    return pad_sequences(sequence, maxlen=max_length)[0]\n",
        "\n",
        "def encode_entities(df):\n",
        "    entity_names = df['entity_name'].unique()\n",
        "    entity_dict = {name: i for i, name in enumerate(entity_names)}\n",
        "    df['entity_encoded'] = df['entity_name'].map(entity_dict)\n",
        "    return df, len(entity_names)\n",
        "\n",
        "def prepare_data(df):\n",
        "    # Generate processed image paths\n",
        "    df['processed_image_path'] = [os.path.join(processed_images_dir, f\"{hashlib.md5(url.encode()).hexdigest()}.npy\") for url in df['image_link']]\n",
        "\n",
        "    # Load and preprocess images\n",
        "    X_img = load_and_preprocess_images(df, image_dir=processed_images_dir)\n",
        "\n",
        "    X_text = np.array([process_text(text) for text in df['text']])\n",
        "    y = pd.get_dummies(df['entity_encoded']).values\n",
        "\n",
        "    print(f\"X_img shape: {X_img.shape}\")\n",
        "    print(f\"X_text shape: {X_text.shape}\")\n",
        "    print(f\"y shape: {y.shape}\")\n",
        "    return X_img, X_text, y\n",
        "\n",
        "def load_and_preprocess_images(df, image_dir='processed_images', target_size=(224, 224)):\n",
        "    images = []\n",
        "    for idx, row in df.iterrows():\n",
        "        image_path = row['processed_image_path']\n",
        "        image_url = row['image_link']\n",
        "        try:\n",
        "            if os.path.exists(image_path):\n",
        "                img_array = np.load(image_path)\n",
        "            else:\n",
        "                img_array = process_image(image_url, target_size)\n",
        "\n",
        "            if img_array.shape == (target_size[0], target_size[1], 3):\n",
        "                images.append(img_array)\n",
        "            else:\n",
        "                logging.warning(f\"Image shape inconsistent for path: {image_path}, shape: {img_array.shape}\")\n",
        "                images.append(np.zeros(target_size + (3,)))\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading/processing image {image_path}: {e}\")\n",
        "            images.append(np.zeros(target_size + (3,)))\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Main execution\n",
        "file_path = '/content/updated_dataset_with_ocr_results (1).csv'\n",
        "\n",
        "try:\n",
        "    df = load_data(file_path)\n",
        "    df, num_entities = encode_entities(df)\n",
        "    X_img, X_text, y = prepare_data(df)\n",
        "\n",
        "    X_img_train, X_img_test, X_text_train, X_text_test, y_train, y_test = train_test_split(\n",
        "        X_img, X_text, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {len(X_img_train)}\")\n",
        "    print(f\"Test samples: {len(X_img_test)}\")\n",
        "    print(f\"Number of entities: {num_entities}\")\n",
        "\n",
        "    np.save('X_img_train.npy', X_img_train)\n",
        "    np.save('X_img_test.npy', X_img_test)\n",
        "    np.save('X_text_train.npy', X_text_train)\n",
        "    np.save('X_text_test.npy', X_text_test)\n",
        "    np.save('y_train.npy', y_train)\n",
        "    np.save('y_test.npy', y_test)\n",
        "\n",
        "    print(\"Data preprocessing completed and saved.\")\n",
        "\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Please check your dataset structure and ensure all required columns are present.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "finally:\n",
        "    print(\"Script execution completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU3VSp1MqPkK"
      },
      "outputs": [],
      "source": [
        "# 1. Model Creation\n",
        "def create_model(img_shape, text_shape, num_entities):\n",
        "    # Image input branch\n",
        "    img_input = layers.Input(shape=img_shape)\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=img_input)\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "    # Text input branch\n",
        "    text_input = layers.Input(shape=(text_shape,))\n",
        "    y = layers.Embedding(input_dim=10000, output_dim=100)(text_input)\n",
        "    y = layers.LSTM(128)(y)\n",
        "    y = layers.Dense(256, activation='relu')(y)\n",
        "\n",
        "    # Combine branches\n",
        "    combined = layers.concatenate([x, y])\n",
        "    z = layers.Dense(128, activation='relu')(combined)\n",
        "    z = layers.Dropout(0.5)(z)\n",
        "    output = layers.Dense(num_entities, activation='sigmoid')(z)\n",
        "\n",
        "    model = Model(inputs=[img_input, text_input], outputs=output)\n",
        "    return model\n",
        "\n",
        "# 2. Model Compilation\n",
        "def compile_model(model):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 3. Model Training\n",
        "def train_model(model, X_img_train, X_text_train, y_train, X_img_val, X_text_val, y_val, epochs=50, batch_size=32):\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "    history = model.fit(\n",
        "        [X_img_train, X_text_train], y_train,\n",
        "        validation_data=([X_img_val, X_text_val], y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return history\n",
        "\n",
        "# Main execution\n",
        "try:\n",
        "    df = load_data(file_path)\n",
        "    df, num_entities = encode_entities(df)\n",
        "    X_img, X_text, y = prepare_data(df)\n",
        "\n",
        "    X_img_train, X_img_test, X_text_train, X_text_test, y_train, y_test = train_test_split(\n",
        "        X_img, X_text, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    img_shape = X_img_train.shape[1:]\n",
        "    text_shape = X_text_train.shape[1]\n",
        "\n",
        "    model = create_model(img_shape, text_shape, num_entities)\n",
        "    model = compile_model(model)\n",
        "\n",
        "    history = train_model(model, X_img_train, X_text_train, y_train, X_img_test, X_text_test, y_test)\n",
        "\n",
        "    model.save('entity_extraction_model.h5')\n",
        "    print(\"Model training completed and saved.\")\n",
        "\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Please check your dataset structure and ensure all required columns are present.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwDiLY9uimdf"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_img_test, X_text_test, y_test):\n",
        "    y_pred = model.predict([X_img_test, X_text_test])\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    print(classification_report(y_true_classes, y_pred_classes))\n",
        "    return y_pred_classes, y_true_classes\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(121)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main execution\n",
        "try:\n",
        "    # Load the model and test data\n",
        "    model = tf.keras.models.load_model('entity_extraction_model.h5')\n",
        "    X_img_test = np.load('X_img_test.npy')\n",
        "    X_text_test = np.load('X_text_test.npy')\n",
        "    y_test = np.load('y_test.npy')\n",
        "\n",
        "    # Load original dataframe to get entity names\n",
        "    df = pd.read_csv('/content/updated_dataset_with_ocr_results (1).csv', sep=',')\n",
        "    class_names = df['entity_name'].unique()\n",
        "\n",
        "    y_pred_classes, y_true_classes = evaluate_model(model, X_img_test, X_text_test, y_test)\n",
        "    plot_confusion_matrix(y_true_classes, y_pred_classes, class_names)\n",
        "\n",
        "    # Note: We can't plot training history here as it's not saved.\n",
        "    # If you want to plot it, you need to save the history in the training step.\n",
        "\n",
        "    print(\"Model evaluation completed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during model evaluation: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}